{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72193457",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b07f4a4e93a3f8fd2075f8da3f9d15cd",
     "grade": false,
     "grade_id": "cell-02adfcc9ad63a2ad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# ECMM426 Computer Vision\n",
    "\n",
    "## Course Assessment\n",
    "\n",
    "This is an autogradable course assessment (CA) for the ECMM426 Computer Vision module, which represents 60% of the overall module assessment.\n",
    "\n",
    "This is an individual exercise and your attention is drawn to the College and University guidelines on collaboration and plagiarism, which are available from the University of Exeter [website](https://www.exeter.ac.uk/students/administration/complaintsandappeals/academicmisconduct/).\n",
    "\n",
    "**Important:**\n",
    "1. Do not change the name of this notebook and the containing folder. The notebook and the folder should respectively be named as **CA.ipynb** and **CA**.\n",
    "2. Do not add and remove/delete any cell. You can work on a draft notebook and only copy the functions/implementations here.\n",
    "3. Do not add your name or student code in the notebook or in the file name.\n",
    "4. Each question asks for one or more functions to be implemented.\n",
    "5. Each question is associated with appropriate marks and clearly specifies the marking criteria. Most of the questions have partial grading.\n",
    "6. Each question specifies a particular type of inputs and outputs which you should regard.\n",
    "7. Each question specifies data for your experimentation and test which you can consider.\n",
    "8. A hidden unit test is going to evaluate if all the desired properties of the required function(s) are met or not.\n",
    "9. If the test passes all the associated marks will be rewarded, if it fails 0 marks will be awarded.\n",
    "10. There is no restriction on the usage of any function from the packages from pip3 distribution.\n",
    "11. While uploading your work on e-Bart, please do not upload the EXCV10 and MaskedFace datasets you use for training your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5201057",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "37f5e4d5d33636e560a9ad54d0f5f094",
     "grade": false,
     "grade_id": "cell-e3e96c66c532b762",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 1 (3 marks)\n",
    "Write a function `add_gaussian_noise(im, m, std)` which will add Gaussian noise with mean `m` and standard deviation `std` to the input image `im` and will return the noisy image. Note that the output image must be of `uint8` type and the pixel values should be normalized in $[0, 255]$.\n",
    "\n",
    "#### Inputs\n",
    "* `im` is a 3 dimensional numpy array of type `uint8` with values in $[0,255]$.\n",
    "* `m` is a real number.\n",
    "* `std` is a real number.\n",
    "\n",
    "#### Outputs\n",
    "* The expected output is a 3 dimensional numpy array of type `uint8` with values in $[0,255]$.\n",
    "\n",
    "#### Data\n",
    "* You can work with the image at `data/books.jpg`.\n",
    "\n",
    "#### Marking Criteria\n",
    "* The output with a particular `m` and `std` should exactly match with the correct noisy image with that `m` and `std` to obtain the full marks. There is no partial marking for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ee866d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ee2911a89460f9a79ee530aabbe1622e",
     "grade": false,
     "grade_id": "cell-7eeea1af3cba818f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Gaussian noise\n",
    "def add_gaussian_noise(im, m, std):\n",
    "    row,col,ch= im.shape\n",
    "    gauss = np.random.normal(m,std,(row,col,ch))\n",
    "    gauss = gauss.reshape(row,col,ch).astype(\"uint8\")\n",
    "    noisy = im + gauss  \n",
    "    return noisy    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21a2a05",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "551a5646967d5d80a93f1f908332b805",
     "grade": true,
     "grade_id": "cell-a77edaa5578e1b3e",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaa6ca0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d7438df731fef80cde6bd2ee48b06bb",
     "grade": true,
     "grade_id": "cell-ad3e75b7c8a46e28",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff0bbb3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1a1f169b9bd28a7bf3c759b399d421c1",
     "grade": false,
     "grade_id": "cell-1cef5e6785f36dd7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 2 (3 marks)\n",
    "Speckle noise is defined as multiplicative noise, having a granular pattern, it is the inherent property of Synthetic Aperture Radar (SAR) imagery. More details on Speckle noise can be found [here](https://en.wikipedia.org/wiki/Speckle_(interference)). Write a function `add_speckle_noise(im, m, std)` which will add Speckle noise with mean `m` and standard deviation `std` to the input image `im` and will return the noisy image. Note that the output image must be of `uint8` type and the pixel values should be normalized in $[0,255]$.\n",
    "\n",
    "#### Inputs\n",
    "* `im` is a 3 dimensional numpy array of type `uint8` with values in $[0,255]$.\n",
    "* `m` is a real number.\n",
    "* `std` is a real number.\n",
    "\n",
    "#### Outputs\n",
    "* The expected output is a 3 dimensional numpy array of type `uint8` with values in $[0,255]$.\n",
    "\n",
    "#### Data\n",
    "* You can work with the image at `data/books.jpg`.\n",
    "\n",
    "#### Marking Criteria\n",
    "* The output with a particular `m` and `std` should exactly match with correct noisy image with that `m` and `std` to obtain the full marks. There is no partial marking for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599a2d6a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a98a6114e438ab0248bfab8f74f459b4",
     "grade": false,
     "grade_id": "cell-4407a7529ab5b81e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def add_speckle_noise(im, m, std):\n",
    "    #row,col,ch = im.shape\n",
    "    gauss = np.random.normal(m,std,im.size)\n",
    "    gauss = gauss.reshape(im.shape[0],im.shape[1],im.shape[2]).astype(\"uint8\")        \n",
    "    noisy = im + im * gauss\n",
    "    return noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfc76f3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc2c6b7e4931268c579597c589abfd3b",
     "grade": true,
     "grade_id": "cell-afda26557d5fb74d",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba70b55b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0b47be80ae0cf95dc96b2e63ffbeab6a",
     "grade": false,
     "grade_id": "cell-e3511b1295336825",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 3 (2 marks)\n",
    "Write a function `cal_image_hist(gr_im)` which will calculate the histogram of pixel intensities of a gray image `gr_im`. Note that the histogram will be a one dimensional array whose length must be equal to the maximum intensity value of `gr_im`.\n",
    "#### Inputs\n",
    "* `gr_im` is a 2 dimensional numpy array of type `uint8` with values in $[0,255]$.\n",
    "\n",
    "#### Outputs\n",
    "* The expected output is a 1 dimensional numpy array of type `uint8`.\n",
    "\n",
    "#### Data\n",
    "* You can play with the image at `data/books.jpg`.\n",
    "\n",
    "#### Marking Criteria\n",
    "* The output should exactly match with correct histogram of a given gray image `gr_im` to obtain the full marks. There is no partial marking for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc0a6f1",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10f7bfd7fbcbf9f096047fe4ec6315f0",
     "grade": false,
     "grade_id": "cell-f8f522d5df185ee4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Image histogram\n",
    "def cal_image_hist(gr_im):\n",
    "    maxi=np.max(gr_im)\n",
    "    histgrm,edges=np.histogram(gr_im,bins=maxi,range=(0,256))\n",
    "    histgrm=histgrm.astype('uint8')\n",
    "    return histgrm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44b4da4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "47070c6bcda8f229f860d9d233dadd4b",
     "grade": true,
     "grade_id": "cell-424ed01ea55a463f",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6ecbcc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d0b1a9b8f712e1b78b9d6c3048add9da",
     "grade": false,
     "grade_id": "cell-c3bc76ebe55d35dc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 4 (3 marks)\n",
    "Write a function `compute_gradient_magnitude(gr_im, kx, ky)` to compute gradient magnitude of the gray image `gr_im` with the horizontal kernel `kx` and vertical kernel `ky`.\n",
    "\n",
    "#### Inputs\n",
    "* `gr_im` is a 2 dimensional numpy array of data type `uint8` with values in $[0,255]$.\n",
    "* `kx` and `ky` are 2 dimensional numpy arrays of data type `uint8`.\n",
    "\n",
    "#### Outputs\n",
    "* The expected output is a 2 dimensional numpy array of the same shape as of `gr_im` and of data type `float64`.\n",
    "\n",
    "#### Data\n",
    "* You can work with the image at `data/shapes.png`.\n",
    "\n",
    "#### Marking Criteria\n",
    "* The output should exactly match with the correct gradient magnitude of a given gray image `gr_im` to obtain the full marks. There is no partial marking for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447a481f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4960046eb6f43cead27141555a97002",
     "grade": false,
     "grade_id": "cell-eccc53aa72c6c5f0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Image gradient magnitude\n",
    "def compute_gradient_magnitude(gr_im, kx, ky):\n",
    "    I_x = cv2.filter2D(gr_im, cv2.CV_8U, kx)\n",
    "    I_y = cv2.filter2D(gr_im, cv2.CV_8U, ky)\n",
    "    sbl=np.hypot(I_x,I_y)\n",
    "    sbl=sbl.astype('float64')    \n",
    "    return sbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03af4dee",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9a3e03ab148188a51d7e016ecfa27b7",
     "grade": true,
     "grade_id": "cell-3c5b1199737d8243",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6ba71c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d90c90c3141e87275afd443dd1ff4313",
     "grade": false,
     "grade_id": "cell-9f8b99fca6851b1c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 5 (2 marks)\n",
    "Write a function `compute_gradient_direction(gr_im, kx, ky)` to compute direction of gradient of the gray image `gr_im` with the horizontal kernel `kx` and vertical kernel `ky`.\n",
    "\n",
    "#### Inputs\n",
    "* `gr_im` is a 2 dimensional numpy array of data type `uint8` with values in $[0,255]$.\n",
    "* `kx` and `ky` are 2 dimensional numpy arrays of data type `uint8`.\n",
    "\n",
    "#### Outputs\n",
    "* The expected output is a 2 dimensional numpy array of same shape as of `gr_im` and of data type `float64`.\n",
    "\n",
    "#### Data\n",
    "* You can work with the image at `data/shapes.png`.\n",
    "\n",
    "#### Marking Criteria\n",
    "* The output should exactly match with the correct gradient direction of a given gray image `gr_im` to obtain the full marks. There is no partial marking for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b173153e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f3220de8340968c8afbf10f6d0c622b",
     "grade": false,
     "grade_id": "cell-1d8d4d0d270a1ba5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Image gradient magnitude\n",
    "def compute_gradient_direction(gr_im, kx, ky):\n",
    "    I_x = cv2.filter2D(gr_im,cv2.CV_64F,kx)\n",
    "    I_y = cv2.filter2D(gr_im,cv2.CV_64F,ky)\n",
    "    mag = cv2.magnitude(I_x, I_y) \n",
    "    ori = np.arctan2(I_y, I_x)\n",
    "    ori=ori.astype('float64')    \n",
    "    return ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d801fdc2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce53443ee8c51e7a27f90cb93e4de566",
     "grade": true,
     "grade_id": "cell-599d2d34653411a2",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1665c926",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e763fc830562920a7219ec4de11a5606",
     "grade": false,
     "grade_id": "cell-ae32b514c2f0feff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 6 (8 marks)\n",
    "Write a function `detect_harris_corner(im, ksize, sigmaX, sigmaY, k)` which will detect the corners in the image `im`. Here `ksize` is the kernel size for smoothing the image, `sigmaX` and `sigmaY` are respectively the standard deviation of the kernal along the horizontal and vertical direction, and `k` is the constant in the Harris criteria. Experiment with your corner detection function on the following image (located at `data/shapes.png`):\n",
    "<img src=\"data/shapes.png\" alt=\"Shapes\" width=\"300\"/>\n",
    "Adjust the parameters of your function so that it can detect all the corners in that image. Please feel free to change the given default parameters and set your best parameters as default. You must not resize the above image and note that the returned output should be an $N \\times 2$ array of type `int64`, where $N$ is the total number of existing corner points in the image; each row of that $N \\times 2$ array should be a Cartesian coordinate of the form $(x, y)$. Also please make sure that your function is rotation invariant which is the fundamental property of the Harris corner detection algorithm.\n",
    "\n",
    "#### Inputs\n",
    "* `im` is a 3 dimensional numpy array of type `uint8` with values in $[0,255]$.\n",
    "* `ksize` is an integer number.\n",
    "* `sigmaX` is an integer number.\n",
    "* `sigmaY` is an integer number.\n",
    "* `k` is a floating number.\n",
    "\n",
    "#### Outputs\n",
    "* The expected output is 2 dimension numpy array of data type `int64` of size $N \\times 2$, whose each row should be a Cartesian coordinate of the form $(x, y)$.\n",
    "\n",
    "#### Data\n",
    "* You can work with the image at `data/shapes.png`.\n",
    "\n",
    "#### Marking Criteria\n",
    "* You will obtain full marks if your function can detect all the existing corners in the image, while the image is being rotated to different angles. There is partial marking for this question, which will depend on the performance of the function on that image rotated to different angles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfa8606",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f14b1555589fd343dcac394960797bb",
     "grade": false,
     "grade_id": "cell-64b592fa3da68f47",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Harris corner detection\n",
    "def detect_harris_corner(im, ksize=5, sigmaX=3, sigmaY=3, k=0.01):\n",
    "    from skimage.feature import corner_peaks\n",
    "    im_gr = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY).astype(np.float32)\n",
    "    \n",
    "    im_gr = cv2.GaussianBlur(im_gr, (ksize, ksize), sigmaX=sigmaX, sigmaY=sigmaY)\n",
    "    \n",
    "    sX = np.array(([-1, 0, 1], [-2, 0, 2], [-1, 0, 1]), dtype=np.float)\n",
    "    \n",
    "    sY = np.array(([-1, -2, -1], [0, 0, 0], [1, 2, 1]), dtype=np.float)\n",
    "    \n",
    "    I_x = cv2.filter2D(im_gr, -1, sX)\n",
    "    I_y = cv2.filter2D(im_gr, -1, sY)\n",
    "    \n",
    "    I_x_I_x = cv2.GaussianBlur(I_x*I_x, (ksize, ksize), sigmaX=sigmaX, sigmaY=sigmaY)\n",
    "    I_y_I_y = cv2.GaussianBlur(I_y*I_y, (ksize, ksize), sigmaX=sigmaX, sigmaY=sigmaY)\n",
    "    I_x_I_y = cv2.GaussianBlur(I_x*I_y, (ksize, ksize), sigmaX=sigmaX, sigmaY=sigmaY)\n",
    "    \n",
    "    determA = I_x_I_x * I_y_I_y - I_x_I_y ** 2\n",
    "    \n",
    "    tA = I_x_I_x + I_y_I_y\n",
    "    \n",
    "    S = determA - k * tA ** 2\n",
    "    \n",
    "    crnr = corner_peaks(S, min_distance=1, threshold_abs=1000000)\n",
    "    Ix, Iy = crnr[:, 1], crnr[:, 0]\n",
    "    Cart_co=np.column_stack((Ix,Iy))\n",
    "    \n",
    "    Cart_co =Cart_co.astype(np.int64)  \n",
    "    \n",
    "    return Cart_co\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cff7a7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a11a0a7b4d55c41200acb966a391c0b",
     "grade": true,
     "grade_id": "cell-f8a94ba1f9bf95d7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769f48c5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c033716cf5b233afd5824b5c7204b15",
     "grade": true,
     "grade_id": "cell-f074d472db3c1382",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5787a69",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "18cf8247fc651980b942b65a5e753b8f",
     "grade": true,
     "grade_id": "cell-0c61667b5eac0095",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85286e4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "758713a32c41ceecece60e86c1af7f75",
     "grade": true,
     "grade_id": "cell-51d2fab12280c427",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20274ac",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ee2602a7f16da9a7b5f0dc3bca39eeaa",
     "grade": true,
     "grade_id": "cell-df725b5321c77ec8",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21814b6c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "648b0357ad2697c325c88e49a98a2e07",
     "grade": true,
     "grade_id": "cell-673193fb6357e2c9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da81aab8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0bded5d3d7e154432089efe108bbfda6",
     "grade": true,
     "grade_id": "cell-d1efeca335920d9c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcc4bfe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "054af299b4d3c72ede71042d931af40e",
     "grade": true,
     "grade_id": "cell-f23b97663dd7e0b9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fffe31",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7916109396c9d8913bfcad88c846b926",
     "grade": false,
     "grade_id": "cell-201a15770d5a24e6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 7 (6 marks)\n",
    "Write a function `compute_homogeneous_rotation_matrix(points, theta)` to compute the rotation matrix in homogeneous coordinate system to rotate a shape depicted with 2 dimensional $(x, y)$ coordinates `points` to an angle $\\theta$ (`theta` in the definition) in the anticlockwise direction about the center of the shape.\n",
    "\n",
    "#### Inputs\n",
    "* `points` is a 2 dimensional numpy array of data type `uint8` with shape $k \\times 2$. Each row of `points` is a Cartesian coordinate $(x, y)$.\n",
    "* `theta` is a floating point number denoting the angle of rotation in degree.\n",
    "\n",
    "#### Outputs\n",
    "* The expected output is a 2 dimensional numpy array of data type `float64` with shape $3 \\times 3$.\n",
    "\n",
    "#### Data\n",
    "* You can work with the 2 dimentional numpy array at `data/points.npy`.\n",
    "\n",
    "#### Marking Criteria\n",
    "* You will obtain the full mark if your rotation matrix exactly matches with the actual rotation matrix. If your matrix does not exactly match, you will not get any mark and there is no martial mark for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b60f6b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "699bb0bbdf80dbd317f53055fd4d09cc",
     "grade": false,
     "grade_id": "cell-dd3cc5100dbcd534",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Homogeneous rotation matrix\n",
    "def compute_homogeneous_rotation_matrix(points, theta):\n",
    "    ix,iy=zip(*points)\n",
    "    av_x=sum(ix)/len(ix)\n",
    "    av_y=sum(iy)/len(iy)\n",
    "    \n",
    "    deg=np.deg2rad(theta)\n",
    "    \n",
    "    cos, sin = np.cos(deg), np.sin(deg)\n",
    "    R = np.array([[cos, -sin,0], [sin, cos,0],[0,0,1]])\n",
    "    Tran=np.array([[1,0,av_x],[0,1,av_y],[0,0,1]])\n",
    "    Tran_inv=np.linalg.inv(Tran)\n",
    "    Matrix=Tran_inv@R@Tran\n",
    "    return Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c392ce",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "63f4c7b15aeff48a321db22653455ecd",
     "grade": true,
     "grade_id": "cell-e622e8a4072442dd",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778e8742",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "134c5091cd2d5513063e4a1f75528fd1",
     "grade": false,
     "grade_id": "cell-0513045479b5c601",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 8 (5 marks)\n",
    "Write a function `compute_sift(im, x, y, feature_width)` to compute a basic version of SIFT-like local features at the locations $(x, y)$ of the RGB image `im` as described in the lecture materials and chapter 7.1.2 of the 2nd edition of Szeliski's book. The parameter `feature_width` is an integer representing the local feature width in pixels. You can assume that `feature_width` will be a multiple of 4 (i.e. every cell of your local SIFT-like feature will have an integer width and height). This is the initial window size you examine around each keypoint. Your implemented function should return a numpy array of shape $k \\times 128$, where $k$ is the number of keypoints $(x, y)$ input to the function.\n",
    "\n",
    "<img src=\"data/notre_dame_interest_points.png\" alt=\"Interest Points\" width=\"300\"/>\n",
    "\n",
    "Please feel free to follow all the minute details of the [SIFT paper](https://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf) in your implementation, but please note that your implementation does not need to exactly match all the details to achieve a good performance. Instead a basic version of SIFT implementation is asked in this exercise, which should achieve a reasonable result. The following three steps could be considered as the basic steps: (1) a $4 \\times 4$ grid of cells, each feature_width/4. It is simply the terminology used in the feature literature to describe the spatial bins where gradient distributions will be described. (2) each cell should have a histogram of the local distribution of gradients in $8$ orientations. Appending these histograms together will give you $4 \\times 4 \\times 8 = 128$ dimensions. (3) Each feature should be normalized to unit length.\n",
    "\n",
    "#### Inputs\n",
    "* `im` is a 3 dimensional numpy array of data type `uint8` with values in $[0,255]$.\n",
    "* `x` is a 2 dimensional numpy array of data type `float64` with shape $k \\times 1$.\n",
    "* `y` is a 2 dimensional numpy array of data type `float64` with shape $k \\times 1$.\n",
    "* `feature_width` is an integer.\n",
    "\n",
    "#### Outputs\n",
    "* The expected output is a 2 dimensional numpy array of data type `float64` with shape $k \\times d$, where $d=128$ is the length of SIFT feature vector.\n",
    "\n",
    "#### Data\n",
    "* You can tune your algorithm/parameters with the image at `data/notre_dame_1.jpg` and interest points at `data/notre_dame_1_to_notre_dame_2.pkl`.\n",
    "\n",
    "#### Marking Criteria\n",
    "* You will get full marks if your output is shape wise consistent with the expected output. This function will further be tested together with the feature matching function to be implemented in the next question. There is no partial marking for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca196b25",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b13a21447cf8876cc6a140aff7a2431a",
     "grade": false,
     "grade_id": "cell-a060cf9577bd1c4b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# SIFT like features\n",
    "def compute_sift(im, x, y, feature_width=16, scales=None):\n",
    "    im=cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n",
    "    S=cv2.SIFT_create()\n",
    "    points=[]\n",
    "    for i in range(len(x)):\n",
    "        points.append(cv2.KeyPoint(x[i][0],y[i][0],feature_width, class_id=0))\n",
    "    points,desp=S.compute(im,points)\n",
    "    desp=desp.astype(np.float64)\n",
    "    return desp\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a919e4a9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6f956894fc80f3044146680653f14f8f",
     "grade": true,
     "grade_id": "cell-7b4c98259bd001ef",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7fb006",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dc8e6ed088ce84f28f8926c8148319b8",
     "grade": false,
     "grade_id": "cell-db113289337db0ed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 9 (10 marks)\n",
    "Write a function `match_features(features1, features2, x1, y1, x2, y2, threshold)` to implement the \"ratio test\" or \"nearest neighbor distance ratio test\" method of matching two sets of local features `features1` at the locations `(x1, y1)` and `features2` at the locations `(x2, y2)` as described in the lecture materials and in the chapter 7.1.3 of the 2nd edition of Szeliski's book.\n",
    "\n",
    "<img src=\"data/notre_dame_correspondance.png\" alt=\"Feature Matching\" width=\"500\"/>\n",
    "\n",
    "The parameters `features1` and `features2` are numpy arrays of shape $k \\times 128$, each representing one set of features. `x1` and `x2` are two numpy arrays of shape $k \\times 1$ respcectively containing the x-locations of `features1` and `features2`. `y1` and `y2` are two numpy arrays of shape $k \\times 1$ respcectively containing the y-locations of `features1` and `features2`. Your function should return two outputs: `matches` and `confidences`, where `matches` is a numpy array of shape $n \\times 2$, where $n$ is the number of matches. The first column of `matches` is an index in `features1`, and the second column is an index in `features2`. `confidences` is a numpy array of shape $k \\times 1$ with the real valued confidence for every match.\n",
    "\n",
    "This function does not need to be symmetric (e.g. it can produce different numbers of matches depending on the order of the arguments). To start with, simply implement the \"ratio test\", equation 7.18 in section 7.1.3 of Szeliski. There are a lot of repetitive features in these images, and all of their descriptors will look similar. The ratio test helps us resolve this issue (also see Figure 11 of David Lowe's [IJCV paper]((https://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf)). Please try to tune your SIFT descriptors and matching algorithm together to obtain a better matching score. You can use the images and correspondences below to tune your algorithm.\n",
    "\n",
    "#### Inputs\n",
    "* `features1` is a 2 dimensional numpy array of data type `float64` with shape $m \\times d$.\n",
    "* `features2` is a 2 dimensional numpy array of data type `float64` with shape $n \\times d$.\n",
    "* `x1` is a 2 dimensional numpy array of data type `float64` with shape $m \\times 1$.\n",
    "* `y1` is a 2 dimensional numpy array of data type `float64` with shape $m \\times 1$.\n",
    "* `x2` is a 2 dimensional numpy array of data type `float64` with shape $n \\times 1$.\n",
    "* `y2` is a 2 dimensional numpy array of data type `float64` with shape $n \\times 1$.\n",
    "* `threshold` is a real number of data type `float64`.\n",
    "\n",
    "#### Outputs\n",
    "* `matches` is a 2 dimensional numpy array of data type `int64`.\n",
    "* `confidences` is a 1 dimensional numpy array of data type `float64`.\n",
    "\n",
    "#### Data\n",
    "* You can tune your algorithm on the images at `data/notre_dame_1.jpg` and `data/notre_dame_2.jpg`, and interest points at `data/notre_dame_1_to_notre_dame_2.pkl` and also on the images at `data/mount_rushmore_1.jpg` and `data/mount_rushmore_2.jpg`, and interest points at `data/mount_rushmore_1_to_mount_rushmore_2.pkl`. Note that the corresponding points within the pickle files are the matching points.\n",
    "\n",
    "#### Marking Criteria\n",
    "* The marking will be based on matching accuracy obtained by the feature description and matching algorithm implemented by you respectively in the previous and this question. There are two test cases (5 marks each) with two different pairs of images and corresponding points, which are provided in the Data section. You will obtain 60% marks if your algorithm can obtain matching accuracy greater than or equal to 50%, 80% marks if your algorithm obtains 70% accuracy or more, and full marks if your algorithm secures 90% matching accuracy or more. You will not obtain any mark if your algorithm can not achieve 50% matching accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf4e63d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "63f75fa3e3abf675fd9cda01849a5661",
     "grade": false,
     "grade_id": "cell-9a95f2fdcb4cf7af",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Feature matching\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "def match_features(features1, features2, x1, y1, x2, y2, threshold=1.0):\n",
    "    \n",
    "    dist = euclidean_distances (features1, features2)    \n",
    "    val = np.argsort(dist, axis=1)\n",
    "    dis_sort = np.take_along_axis(dist, val, axis=1)    \n",
    "    res = dis_sort[:, 0] / dis_sort[:, 1]    \n",
    "    r = res < threshold        \n",
    "    Conf = 1 / res[r]\n",
    "    k = Conf.shape[0]\n",
    "    mat = np.zeros((k, 2), dtype=int)        \n",
    "    mat[:, 0] = np.where(r)[0]\n",
    "    mat[:, 1] = val[r, 0]        \n",
    "    r = (-Conf).argsort()\n",
    "    mat = mat[r, :]\n",
    "    Conf = Conf[r]\n",
    "    mat=mat.astype(np.int64)\n",
    "    Conf=Conf.astype(np.float64)\n",
    "    return mat, Conf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a70cc18",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "13a0ebd6c76e5c44149379447cf1272c",
     "grade": true,
     "grade_id": "cell-321a8f0b2c0f9ef9",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50ff72d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a3d943f3da3580737eecc7f605f8c6fc",
     "grade": true,
     "grade_id": "cell-e3246502d1707318",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435a62c9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b5e204294b4f5f893c140bf76d2af93",
     "grade": true,
     "grade_id": "cell-e0b2bc03a9adc29a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839c1829",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d439cbeec0045d70140bcd595421c56c",
     "grade": true,
     "grade_id": "cell-30926a4f2a0dc63a",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7852270",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "80c8f28edf47259036f8913272e2cee1",
     "grade": true,
     "grade_id": "cell-742bd8eefb42996e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ffe4e3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "78c39ad170b2cfed36e9ff3e7e14235a",
     "grade": true,
     "grade_id": "cell-c3eed272abd24f64",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d79d3b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4f91fb4dd15e8f79927e99d94b97ec57",
     "grade": false,
     "grade_id": "cell-66a817639d9481fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 10 (5 marks)\n",
    "Write a function `find_affine_transform(x1, y1, x2, y2)` which will return the homogeneous affine transformation matrix $T$ from $(x_1,y_1)$ to $(x_2,y_2)$, where $(x_1,y_1)$ and $(x_2,y_2)$ are the 2 dimensional corresponding/matching points from two different images. The technique for computing transformation matrix was covered in the lectures, which is an approximation of any generic affine transformation matrix and can be done with the help of homogeneous coordinate.\n",
    "\n",
    "#### Inputs\n",
    "* `x1`, `y1`, `x2`, `y2` are 2 dimensional numpy arrays of shape $N \\times 1$ of data type `float64`.\n",
    "\n",
    "#### Outputs\n",
    "* This function should return a 2 dimensional numpy array of shape $3 \\times 3$ of data type `float64`.\n",
    "\n",
    "#### Data\n",
    "* You can consider the matching points at `data/notre_dame_1_to_notre_dame_2.pkl` for tuning your algorithm.\n",
    "\n",
    "#### Marking Criteria\n",
    "* You will obtain full marks if and only if the homogeneous affine transformation matrix calculated by your algorithm exactly matches with the correct one. There is no partial marking for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862f327d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6fe74a51880c7810183f40fe7fb87337",
     "grade": false,
     "grade_id": "cell-69420f00a0b4e180",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Affine transformation\n",
    "def find_affine_transform(x1, y1, x2, y2):\n",
    "    vs1=np.vstack((x1.T,y1.T))\n",
    "    vs1=np.vstack((vs1,np.ones(len(x1))))\n",
    "    vs2=np.vstack((x2.T,y2.T))\n",
    "    vs2=np.vstack((vs2,np.ones(len(x2))))\n",
    "    inv_vs=np.linalg.pinv(vs1)\n",
    "    mat=vs2@inv_vs\n",
    "    return mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd496028",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "736244dc35abd822845bcf61dd525958",
     "grade": true,
     "grade_id": "cell-8e320d18dbd1d6cb",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b49c18",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2fb3b71644d0912702637c7a2df263ff",
     "grade": false,
     "grade_id": "cell-6adcd7879c172b75",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 11 (10 marks)\n",
    "Write a function `make_bovw_spatial_histogram(im, locations, clusters, division)` to create bag of visual words representation of an image `im` whose features are located at `locations` and the quantized labels of those features are stored in `clusters`. You have to build the histogram based on the division information provided in `division`. For example, if `division = [2, 3]`, you have to imagine dividing the image along Y-axis in $2$ parts and along X-axis in $3$ parts (as shown in the right most figure below), else if `division = [2, 2]`, you have to imagine dividing the image in $2$ parts along both the axes, else if `division = [1, 1]`, you just compute the bag-of-visual-words histogram on the entire image without dividing into any parts.\n",
    "\n",
    "<img src=\"data/spatial_histogram.png\" alt=\"Spatial Histogram\" width=\"1000\"/>\n",
    "\n",
    "#### Inputs\n",
    "* `im` is a 3 dimensional numpy array of data type `uint8`.\n",
    "* `locations` is a 2 dimensional numpy array of shape $N \\times 2$ of data type `int64`, whose each row is a Cartesian coordinate $(x,y)$.\n",
    "* `clusters` is a 1 dimensional numpy array of shape $(N,)$ of data type `int64`, whose each element indicates the quantized cluster id.\n",
    "* `division` is a list of integer of length 2.\n",
    "\n",
    "#### Outputs\n",
    "* This function should return a 1 dimensional numpy array of data type `int64`.\n",
    "\n",
    "#### Data\n",
    "* There is no specific data for this question. However, you can create data on one of the images available inside the `data` folder.\n",
    "\n",
    "#### Marking Criteria\n",
    "* There are four test cases which will call the above functionn to calculate bag-of-visual-words spatial histograms on the image `im` imagining its coarse and fine divisions which will be provided while calling the function. In each test case, your spatial histogram should be exactly matched with the correct spatial histogram to obtain the full marks. Coarser test cases contain lower weightage compared to their finer counter parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf11775e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ef10999fcd92b1833108194654161d4",
     "grade": false,
     "grade_id": "cell-0e96f0362680e419",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "def make_bovw_spatial_histogram(im, locations, clusters, division):\n",
    "    \n",
    "    n=np.unique(clusters).size\n",
    "    image=cv2.cvtColor(im,cv2.COLOR_RGB2GRAY)\n",
    "    S=cv2.SIFT_create()    \n",
    "    dy=division[0]\n",
    "    dx=division[1]    \n",
    "    ix=image.shape[1]\n",
    "    iy=image.shape[0]    \n",
    "    al=[]    \n",
    "    lis_descp=[]\n",
    "    \n",
    "    for i in range(dy):\n",
    "        for j in range(dx):             \n",
    "            image2=image[i*(iy//dy):(i+1)*(iy//dy),j*(ix//dx):(j+1)*(ix//dx)]            \n",
    "            ran1=range(i*(iy//dy),(i+1)*(iy//dy))\n",
    "            ran2=range(j*(ix//dx),(j+1)*(ix//dx))\n",
    "            p=[]\n",
    "            q=[]            \n",
    "            \n",
    "            for k in range(len(locations)):\n",
    "                if locations[k][1] in ran1 and locations[k][0] in ran2:\n",
    "                    p.append(float(locations[k][0]))\n",
    "                    q.append(float(locations[k][1]))                    \n",
    "            \n",
    "            key_point=[]\n",
    "            for a in range(len(p)):\n",
    "                key_point.append(cv2.KeyPoint(p[a],q[a],16,class_id=0))                \n",
    "            key_point,decp=S.compute(image2,key_point)\n",
    "            al.append(decp.shape[0])\n",
    "            lis_descp.append(decp)            \n",
    "    \n",
    "    descrp=np.array(lis_descp[0])\n",
    "    for descriptor in lis_descp[1:]:\n",
    "        descrp=np.vstack((descrp,descriptor))    \n",
    "    \n",
    "    k_m=KMeans(n_clusters=n)\n",
    "    \n",
    "    k_m.fit(descrp)\n",
    "    hist_r=k_m.labels_        \n",
    "    quad_histogram=[]\n",
    "    tmp=[]\n",
    "    z=0\n",
    "    \n",
    "    for i in range(len(al)):\n",
    "        tmp=hist_r[z:z+al[i]]        \n",
    "        z+=al[i]\n",
    "        tmp=tmp.tolist()\n",
    "        quad_histogram.append([tmp.count(i) for i in range(n)])        \n",
    "    \n",
    "    lis=[point for sublist in quad_histogram for point in sublist]\n",
    "    his =np.array(lis)\n",
    "    his=his.astype(np.int64)\n",
    "        \n",
    "    return his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47660e61",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "60a71b53727f3a9aa4b5e80e77e753ac",
     "grade": true,
     "grade_id": "cell-a60e8d2f1ae4e282",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f7428e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4235b068b23d4beaf130232d07793cb3",
     "grade": true,
     "grade_id": "cell-49e01874c90ffaa9",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe263c1c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "afa091ea9b4a376a13c5659b0775cef8",
     "grade": true,
     "grade_id": "cell-59db309d7efddab7",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4efbb50",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6fe5f06be7bb7dc0a97665b5603950aa",
     "grade": true,
     "grade_id": "cell-ada8a90ac0f97002",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553f1dac",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "36b2417ca05dff50f936982f2183fbb3",
     "grade": false,
     "grade_id": "cell-d44d6af26596e5be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 12 (3 marks)\n",
    "Write a function `histogram_intersection_kernel(X, Y)` to compute Histogram Intersection Kernel which is also known as the Min Kernel and is calculated by\n",
    "$$k(x, y)=\\sum_{i=1}^d \\min(x_i, y_i)$$\n",
    "where $d$ is the length of the feature vector.\n",
    "\n",
    "#### Inputs\n",
    "* `X` and `Y` are 2 dimensional numpy arrays of shape $M \\times d$ and $N \\times d$ respectively of data type `int64`.\n",
    "\n",
    "#### Outputs\n",
    "* This function should return a 2 dimensional numpy array of shape $M \\times N$ of data type `float64`.\n",
    "\n",
    "#### Data\n",
    "* There is no specific data for this question. However, you can create your own data `X` and `Y` satisfying the input criteria.\n",
    "\n",
    "#### Marking Criteria\n",
    "* You will obtain full marks if and only if the kernel matrix calculated by your function exactly matches with the correct one. There is no partial marking for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e25f8d5",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb0e5a0501f081c8f0f8678abdb2900c",
     "grade": false,
     "grade_id": "cell-ea9f47767182146f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Histogram intersection kernel\n",
    "def histogram_intersection_kernel(X, Y):\n",
    "    kr=np.zeros((X.shape[0],Y.shape[0]))\n",
    "    \n",
    "    for n in range(X.shape[1]):\n",
    "        b1=X[:,n].reshape(-1,1)\n",
    "        b2=Y[:,n].reshape(-1,1)\n",
    "        \n",
    "        kr=kr+np.minimum(b1,b2.T)\n",
    "    \n",
    "    return kr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c18296f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8d40cf36466aa494a11846b4732e6ac",
     "grade": true,
     "grade_id": "cell-ce0523bb5bc169ef",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754ea52d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8a98d7ca175a5cc69f3be983b25007ec",
     "grade": false,
     "grade_id": "cell-6c100514ed2bfb2b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 13 (1 mark)\n",
    "Write a function `generalized_histogram_intersection_kernel(X, Y, alpha)` to compute Generalized Histogram Intersection Kernel which is computed by\n",
    "$$k(x, y)=\\sum_{i=1}^d \\min(|x_i|^\\alpha, |y_i|^\\alpha)$$\n",
    "where $d$ is the length of the feature vector.\n",
    "\n",
    "#### Inputs\n",
    "* `X` and `Y` are 2 dimensional numpy arrays of shape $M \\times d$ and $N \\times d$ respectively of data type `int64`.\n",
    "* `alpha` is a real number of data type `float`.\n",
    "\n",
    "#### Outputs\n",
    "* This function should return a 2 dimensional numpy array of shape $M \\times N$ of data type `float64`.\n",
    "\n",
    "#### Data\n",
    "* There is no specific data for this question. However, you can create your own data `X` and `Y` satisfying the input criteria.\n",
    "\n",
    "#### Marking Criteria\n",
    "* You will obtain full marks if and only if the kernel matrix calculated by your function exactly matches with the correct one. There is no partial marking for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cfdcf5",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bc745c147a78cfb514f8e69d108535e5",
     "grade": false,
     "grade_id": "cell-002da2406b7fde7e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Generalized histogram intersection kernel\n",
    "def generalized_histogram_intersection_kernel(X, Y, alpha):\n",
    "    his=histogram_intersection_kernel(np.abs(X)*alpha, np.abs(Y)*alpha)\n",
    "    \n",
    "    return his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294d1b7e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f5df731d29bd7a96ae30b236761ea938",
     "grade": true,
     "grade_id": "cell-7e0c00f42e3b8872",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1701be46",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2e35c080731e445b8b6b0a0528e76c54",
     "grade": false,
     "grade_id": "cell-8a3372fac153b97d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 14 (1 mark)\n",
    "Write a function `train_gram_matrix(X_tr, X_te)` which will compute the train gram matrix using the Histogram Intersection Kernel implemented above.\n",
    "\n",
    "#### Inputs\n",
    "* `X_tr` and `X_te` are 2 dimensional numpy arrays of shape $M \\times d$ and $N \\times d$ respectively of data type `int64`.\n",
    "\n",
    "#### Outputs\n",
    "* This function should return a 2 dimensional numpy array of data type `float64`.\n",
    "\n",
    "#### Data\n",
    "* There is no specific data for this question. However, you can create your own data `X_tr` and `X_te` satisfying the input criteria.\n",
    "\n",
    "#### Marking Criteria\n",
    "* You will obtain full marks if and only if the kernel matrix calculated by your function exactly matches with the correct one. There is no partial marking for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5624bf28",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bae5c8df3bf57e83ba67d8a61cfc6755",
     "grade": false,
     "grade_id": "cell-093d79e82cd16400",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Train gram matrix\n",
    "def train_gram_matrix(X_tr, X_te):\n",
    "    his=histogram_intersection_kernel(X_tr,X_te)\n",
    "    mat=his.T.dot(his)\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699c44de",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b507f64e2660e64da813d02d0b8e885a",
     "grade": true,
     "grade_id": "cell-7e328f69d465734e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a700cc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9c6eb10ef71e5e65ee187a179cfd059b",
     "grade": false,
     "grade_id": "cell-ec232a09ce979306",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 15 (1 mark)\n",
    "Write a function `test_gram_matrix(X_tr, X_te)` which will compute the test gram matrix using the Histogram Intersection Kernel implemented above.\n",
    "\n",
    "#### Inputs\n",
    "* `X_tr` and `X_te` are 2 dimensional numpy arrays of shape $M \\times d$ and $N \\times d$ respectively of data type `int64`.\n",
    "\n",
    "#### Outputs\n",
    "* This function should return a 2 dimensional numpy array of data type `float64`.\n",
    "\n",
    "#### Data\n",
    "* There is no specific data for this question. However, you can create your own data `X_tr` and `X_te` satisfying the input criteria.\n",
    "\n",
    "#### Marking Criteria\n",
    "* You will obtain full marks if and only if the kernel matrix calculated by your function exactly matches with the correct one. There is no partial marking for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aee19f0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "800c6475fa61afc39a0c70c331ed6d2d",
     "grade": false,
     "grade_id": "cell-b5b0e0bdc5001b77",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test gram matrix\n",
    "def test_gram_matrix(X_tr, X_te):\n",
    "    his=histogram_intersection_kernel(X_tr,X_te)\n",
    "    arr=his.T.dot(his)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8a73c1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "164ee5d120a8d51e748d3fa62c71c296",
     "grade": true,
     "grade_id": "cell-bf86e4f46bfd3819",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78607ca",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5f441c800ecb234f29722918488c9394",
     "grade": false,
     "grade_id": "cell-9db6b0e8cd8f1869",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 16 (5 marks)\n",
    "Let $p_1 = (x_1, y_1)$ and $p_2 = (x_2, y_2)$ be two sets of corresponding/matching points respectively from two images $I_1$ and $I_2$. Further, let $(R_1, T_1)$ and $(R_2, T_2)$ be the camera parameters resepentively for the images $I_1$ and $I_2$. Write a function `reconstruct_3d(p1, p2, R1, R2, T1, T2)` to find the 3 dimensional coordinates of the points in $p_1$ and/or $p_2$.\n",
    "\n",
    "#### Inputs\n",
    "* $p_1$ and $p_2$ are 2 dimensional numpy arrays of shape $N \\times 2$ of data type `float32`.\n",
    "* $R_1$ and $R_2$ are 2 dimensional numpy arrays of shape $2 \\times 3$ of data type `float32`.\n",
    "* $T_1$ and $T_2$ are 1 dimensional numpy arrays of shape $(2,)$ of data type `float32`.\n",
    "\n",
    "#### Outputs\n",
    "* This function should return a numpy array of shape $N \\times 3$ of data type `float32`.\n",
    "\n",
    "#### Data\n",
    "* There is not particular data for this question.\n",
    "\n",
    "#### Marking Criteria\n",
    "* You will get full marks if and only if answer returned by the implemented function matches with the true answer. There is no partial marking for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae70a198",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a784d58173ba2200f32ce49ffb63ba2",
     "grade": false,
     "grade_id": "cell-a59ef7719e9e587a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 3D reconstruction\n",
    "def reconstruct_3d(p1, p2, R1, R2, T1, T2):\n",
    "    R=np.concatenate((R1,R2),axis=0)\n",
    "    PT=np.concatenate((np.transpose(p1-T1),np.transpose(p2-T2)),axis=0)\n",
    "    contr=np.transpose(np.matmul(np.linalg.pinv(R),PT))\n",
    "    return contr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555369ec",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d8fbd7d50b6c0edef9bdf865086ea4c",
     "grade": true,
     "grade_id": "cell-ae3dffa9d4f74e3c",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ad2872",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d86f3c43a653eb66c96c993bcc6d31ea",
     "grade": false,
     "grade_id": "cell-8a10c608cb9a6a0d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 17 (4 marks)\n",
    "Write a function `train_cnn(model, train_loader)` to train the following version of the Residual Network (ResNet) model on the [EXCV10](https://empslocal.ex.ac.uk/people/staff/ad735/ECMM426/EXCV10.zip) (Exeter Computer Vision 10) dataset (available at this [link](https://empslocal.ex.ac.uk/people/staff/ad735/ECMM426/EXCV10.zip)). At the end of the training, this function should save the best weights of the trained CNN at: `data/weights_resnet.pth`. The [EXCV10](https://empslocal.ex.ac.uk/people/staff/ad735/ECMM426/EXCV10.zip) dataset contains 10000 images from 10 classes which are further split into train (available at `train/` folder; total 8000 images with 800 images/class) and validation (available at `val/` folder; total 2000 images with 200 images/class) sets. For training your model, please feel free to decide your optimal hyperparameters, such as the number of epochs, type of optimisers, learning rate scheduler etc within the function, which can be done to optimise the performance of the model on the validation set.\n",
    "#### Inputs\n",
    "* `model` is an instantiation of ResNet class which can be created as follows: `ResNet(block=BasicBlock, layers=[1, 1, 1], num_classes=num_classes)`. An example of this can be found in the snippet in the following cell.\n",
    "* `train_loader` is the training data loader. You can create the dataset and data loader for your training following the example in the cell below. Feel free to try other data augmentation and regularization techniques to train a better model.\n",
    "\n",
    "#### Outputs\n",
    "* This function should not necessarily return any output, instead it should save your best model at `data/weights_resnet.pth`.\n",
    "\n",
    "#### Data\n",
    "* You can train your model on the data available at https://empslocal.ex.ac.uk/people/staff/ad735/ECMM426/EXCV10.zip. As EXCV10 dataset is quite large in size, donot upload it with your submission.\n",
    "\n",
    "#### Marking Criteria\n",
    "* You will obtain full marks if the model weights saved at `data/weights_resnet.pth` can be loaded to a new instantiation of the model `ResNet(block=BasicBlock, layers=[1, 1, 1], num_classes=num_classes)`. You will not get any mark if your model is missing or saved in a different location or it cannot be loaded to the aforementioned model instance. Additionally, the quality of your trained model will be examined in the next question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3afe36",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "122e1f37baffd76d0bc3bdd94790e4ad",
     "grade": false,
     "grade_id": "cell-7b71cb4a01ea3b5a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# ResNet model\n",
    "from ca_utils import ResNet, BasicBlock\n",
    "model = ResNet(block=BasicBlock, layers=[1, 1, 1], num_classes=1000)  # change num_classes if needed, this is an example\n",
    "\n",
    "# Dataset\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "# Vanilla image transform\n",
    "image_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Dataset\n",
    "import torchvision\n",
    "train_data = torchvision.datasets.ImageFolder('train/', transform=image_transform)\n",
    "\n",
    "# Data loader\n",
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72411437",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "73bc97a1efa842e98a676bef9ebc57bc",
     "grade": false,
     "grade_id": "cell-4d32274b0fd42843",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "class AvgMeter(object):\n",
    "    \n",
    "    def _init_(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.res = 0\n",
    "        self.avrg = 0\n",
    "        self.total = 0\n",
    "        self.iter = 0\n",
    "\n",
    "    def update(self, res, n=1):\n",
    "        self.res = res\n",
    "        self.total += res * n\n",
    "        self.iter += n\n",
    "        self.avrg = self.total / self.iter\n",
    "\n",
    "\n",
    "\n",
    "def train_cnn(model, train_loader):\n",
    "    learnrate = 0.0017\n",
    "    wghtdecay = 0.0012\n",
    "    \n",
    "    device = torch.device(\"cuda\")\n",
    "    \n",
    "    \n",
    "    img_trans = transforms.Compose([transforms.RandomCrop(64),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.RandomHorizontalFlip(p=0.5), transforms.ColorJitter(brightness=.5,hue=.3),transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    \n",
    "    optim_ft = optim.SGD(model.parameters(),learnrate, momentum=0.9)\n",
    "\n",
    "    \n",
    "    learnrate_schdlr = lr_scheduler.StepLR(optim_ft, step_size=15, gamma=1.0)\n",
    "    epoch_val= 50\n",
    "    intial_loss=999\n",
    "    model=model.to(device)\n",
    "    try:\n",
    "        os.remove('data/weights_resnet.pth')\n",
    "    except(FileNotFoundError):\n",
    "        t=0\n",
    "    for epoch in range(1, epoch_val+ 1):\n",
    "        loss = AvgMeter()\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        intial_loss=999\n",
    "        for data, target in train_loader:\n",
    "            model.to(device)\n",
    "            data, target = data.to(device), target.to(device)  \n",
    "            output = model(data) \n",
    "            loss_this= F.cross_entropy(output, target)\n",
    "            optim_ft.zero_grad()\n",
    "            loss_this.backward()\n",
    "\n",
    "            optim_ft.step()\n",
    "            learnrate_schdlr.step()\n",
    "            loss.update(loss_this.item(), target.shape[0])\n",
    "        if loss.avrg<=intial_loss:\n",
    "            intial_loss=loss.avrg\n",
    "            if epoch==1:\n",
    "                torch.save(model.state_dict(), 'data/weights_resnet.pth')\n",
    "            else:\n",
    "                os.remove('data/weights_resnet.pth')\n",
    "                torch.save(model.state_dict(), 'data/weights_resnet.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef33b25",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cfcbc9c388a7d487fc988ce2319269a3",
     "grade": true,
     "grade_id": "cell-ac88643e76933161",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8def58b2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b20aaaf5e526af9a2d99c5e5bb9d6a76",
     "grade": false,
     "grade_id": "cell-8f3e37cc7454f448",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 18 (12 marks)\n",
    "Write a function `test_cnn(model, test_loader)` which will return the predicted labels by the `model` that you trained in the previous question for all the images supplied in the `test_loader` object. The test set will contain 3000 images (300 images/class) from the same distribution as of the [EXCV10](https://empslocal.ex.ac.uk/people/staff/ad735/ECMM426/EXCV10.zip) dataset.\n",
    "\n",
    "#### Inputs\n",
    "* `model` is an instantiation of ResNet class which can created as follows `ResNet(block=BasicBlock, layers=[1, 1, 1], num_classes=num_classes)`. An example of this can be found in the cell below.\n",
    "* `test_loader` is the data loader containing test data. The test data loader can be created following the example in the cell below. We will only use vanilla transformation to the test dataset.\n",
    "\n",
    "#### Outputs\n",
    "* This function should return a 1 dimensional numpy array of data type `int64` containing the predicted labels of the images in the `test_loader` object.\n",
    "\n",
    "#### Data\n",
    "* You can test your model on the `val` set of the data available at https://empslocal.ex.ac.uk/people/staff/ad735/ECMM426/EXCV10.zip. As EXCV10 dataset is quite large in size, please donot upload it with your submission.\n",
    "\n",
    "#### Marking Criteria\n",
    "* Your model will be tested based on average classification accuracy on a test set of 3000 images (300 images/class). You will obtain 50% marks if the obtained accuracy of your model on the test set is greater than or equal to 50%, 60% marks if your model obtains 55% accuracy or more, 70% marks if your model gets 60% accuracy or more, 80% marks if your model acquires 65% accuracy or more, 90% marks if your model wins 70% accuracy or more, and full marks if your model secures 75% accuracy or more. You will not obtain any mark if your model can not achieve 50% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44166879",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7546ccf47972d7d05449a3031d36a6ca",
     "grade": false,
     "grade_id": "cell-418180b7807c1d03",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Dataset\n",
    "from PIL import Image\n",
    "from torchvision import transforms, datasets\n",
    "class EXCV10TestImageFolder(datasets.ImageFolder):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(EXCV10TestImageFolder, self).__init__(*args, **kwargs)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.imgs[index][0]\n",
    "        pic = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(pic)\n",
    "        return img\n",
    "    \n",
    "# Vanilla image transform\n",
    "image_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    \n",
    "# Dataset\n",
    "test_data = EXCV10TestImageFolder('val/', transform=image_transform)\n",
    "\n",
    "# Data loader\n",
    "from torch.utils.data import DataLoader\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da16d82",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "163d2867fa72a1da3b211a64c3c30d58",
     "grade": false,
     "grade_id": "cell-4bc52a72e10b0231",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def test_cnn(model, test_loader):\n",
    "    import itertools\n",
    "  \n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "    model.to(device)\n",
    "    predict_labels=[]\n",
    "    model.eval()\n",
    "    for data in test_loader:\n",
    "        \n",
    "        data= data.to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(data)\n",
    "\n",
    "        p = out.argmax(dim=1, keepdim=True) \n",
    "        h=p.tolist()\n",
    "        List_flat = list(itertools.chain(*h))\n",
    "\n",
    "        for i in List_flat:\n",
    "            predict_labels.append(i)\n",
    "\n",
    "    predict_labels=np.array(predict_labels)\n",
    "    predict_labels=predict_labels.astype('int64')\n",
    "\n",
    "    return predict_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20b2630",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "90c26381ba05a97c2a48e3d3dd34f8b6",
     "grade": true,
     "grade_id": "cell-d9ed0c43b4c6e040",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efb0924",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3d7c56206e116902af4703c6d032ce94",
     "grade": true,
     "grade_id": "cell-a603726e91aa21a6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a11f0f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "30b80aeea6a4d3a99c0b83a8399969d5",
     "grade": true,
     "grade_id": "cell-57f81fad25de6e73",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3a2e5c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d2cb38e9e946967ec582130fa7bb393e",
     "grade": true,
     "grade_id": "cell-c32643caf64fffd2",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847c6819",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bc07d3da7cf88af87b0855096d18682e",
     "grade": true,
     "grade_id": "cell-f47be569bde61e82",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a8a7c3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "936816a7604d0a414b66f29b718b6dad",
     "grade": true,
     "grade_id": "cell-466641090eb4b8bb",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f145cb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d4ea4bea7eb5a61f800ca074af31f481",
     "grade": false,
     "grade_id": "cell-c0c5a0af68bfac8d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 19 (16 marks)\n",
    "Write a function `count_masks(dataset)` which will count the number of faces correctly wearing mask (`with_mask` class), without mask (`without_mask` class) and incorrectly wearing mask (`mask_weared_incorrect` class) in the list of images `dataset` which is an instantiation of the `MaskedFaceTestDataset` class shown below. (**Hint**: You are expected to implement a 3 class (4 class with background) masked face detector which can detect the aforementioned categories of objects in a given image. However, you are absolutely free to be more innovative and come out with different solutions for this problem.)\n",
    "\n",
    "<img src=\"data/mask.png\" alt=\"Mask\" width=\"800\"/>\n",
    "\n",
    "#### Inputs\n",
    "* `dataset` is an object of the `MaskedFaceTestDataset` class shown in the cell below.\n",
    "\n",
    "#### Outputs\n",
    "* This function should return a 2 dimensional numpy array of shape $N \\times 3$ of data type `int64` whose values should respectively indicate the number of faces wearing mask, without mask and incorrectly wearing mask.\n",
    "\n",
    "#### Data\n",
    "* You can train and test your model on the data available at https://empslocal.ex.ac.uk/people/staff/ad735/ECMM426/MaskedFace.zip. This dataset contains some images and corresponding annotations (locations together with category information) of masked faces, which are split into `train` and `val` subsets. You can train your model on `train` set and decide your hyperparameters on the `val` sets. As MaskedFace dataset is quite large in size, please donot upload it with your submission.\n",
    "\n",
    "#### Marking Criteria\n",
    "* The evaluation will be done based on Mean Absolute Percentage Error (MAPE) which is defined as follows:\n",
    "$$\\text{MAPE} = \\frac{1}{n}\\sum_{t=1}^n \\left|\\frac{A_t - P_t}{\\max(A_t, 1)}\\right| \\times 100 $$\n",
    "where $A_t$ is the true number and $P_t$ is the predicted number of the corresponding class $t$ in an image. For each image in `dataset`, MAPE will be computed, which will be averaged over all the images in `dataset`. You will obtain 50% marks if the obtained average MAPE of your model on the test set is lower than or equal to 30%, 62.5% marks if your model obtains 25% MAPE or less, 75% marks if your model gets 20% MAPE or less, 87.5% marks if your model acquires 15% MAPE or less, and full marks if your model secures 10% MAPE or less. You will not obtain any mark if your model can not achieve 30% MAPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b70d36",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4d0e94a10d676a58553501127d98fd5d",
     "grade": false,
     "grade_id": "cell-a5f52ba49b912893",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Dataset\n",
    "import os, glob\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "class MaskedFaceTestDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        super(MaskedFaceTestDataset, self).__init__()\n",
    "        self.imgs = sorted(glob.glob(os.path.join(root, '*.png')))\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.imgs[index]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9275ff36",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "916d53421e684eac2a7466b5cf679d81",
     "grade": false,
     "grade_id": "cell-04285181322066d5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Count masked faces\n",
    "#link for weights https://drive.google.com/file/d/1nIGENPAQUXu8YvvzISRsbH8AoQoLR4dm/view?usp=sharing\n",
    "#!wget https://drive.google.com/file/d/1nIGENPAQUXu8YvvzISRsbH8AoQoLR4dm/view?usp=sharing\n",
    "def count_masks(test_dataset):\n",
    "    class_str2num = {'with_mask': 1, 'without_mask': 2, 'mask_weared_incorrect': 3}\n",
    "    class_num2str = {v: k for k, v in class_str2num.items()}\n",
    "\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "    num_classes = len(class_str2num) + 1\n",
    "\n",
    "    model = get_model(num_classes)\n",
    "    cp = torch.load(\"data/weights_mask.pth\", map_location=torch.device(\"cpu\"))\n",
    "    model.load_state_dict(cp)\n",
    "    model.to(device)\n",
    "\n",
    "    pred_cls=np.zeros((len(test_dataset),3),dtype='int64')\n",
    "    c=[]\n",
    "    model = model.cpu()\n",
    "    model.eval()\n",
    "\n",
    "    for i in range(len(test_dataset)):\n",
    "        img, _ = test_dataset[i]\n",
    "        with torch.no_grad():\n",
    "            prediction = model([img])\n",
    "        x=prediction[0]['labels'].tolist()\n",
    "        pred_cls[i][0]=x.count(1)\n",
    "        pred_cls[i][1]=x.count(2)\n",
    "        pred_cls[i][2]=x.count(3)\n",
    "\n",
    "    return pred_cls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2018a7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "adcbc8ce33e1f3854a02e13aa9b9f656",
     "grade": true,
     "grade_id": "cell-5f48c3e6ef3435ea",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32c69d0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d23adbae04192199958693af521d691f",
     "grade": true,
     "grade_id": "cell-c64fa7ff5042255c",
     "locked": true,
     "points": 8,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d39f86",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b98d3e950240c7144572ab5ed2f7bd42",
     "grade": true,
     "grade_id": "cell-e3fcd145196897b8",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54e699a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "75f11263aef2060249167352fe894175",
     "grade": true,
     "grade_id": "cell-19dcf73f57f687fa",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626e1175",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70b1a275601c17c9babf15bed48264c9",
     "grade": true,
     "grade_id": "cell-a8faf4bd17f0dc76",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afed6573",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "777aaa29a418de8b3aba352f2c0f5964",
     "grade": true,
     "grade_id": "cell-cb29738c18d73803",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Please leave this cell as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2d5ffc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6bc75683099cebbef47e2e929907572b",
     "grade": false,
     "grade_id": "cell-fd2525614f9ebd17",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Checkpoints\n",
    "\n",
    "Checkpoints are very **IMPORTANT** for this course assessment. This step will ensure that you have implemented all the required functions and their expected outputs are structurally correct i.e. the outputs are consistent from shape, datatype and dimensionality perspective. However, passing these checkpoints will not ensure your implementations or answers are correct, which will be further checked via hidden unit tests after the submission. Please run the following two cells sequentially to run the checkpoints. \n",
    "\n",
    "Please note that the execution of the second cell **should not take more than one minute**, which is actually the last checkpoint.\n",
    "\n",
    "Initially, when none of the above functions is implemented, executing the following two cells should produce the following output:\n",
    "<div style=\"text-align: left;\"><img src=\"data/initial_log.png\" alt=\"Initial Log\" width=\"700\"/></div>\n",
    "\n",
    "Once you have all the required functions correctly implemented, executing the following two cells should produce the following output:\n",
    "<div style=\"text-align: left;\"><img src=\"data/final_log.png\" alt=\"Final Log\" width=\"800\"/></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ea4c98",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "410593a86f1699450a52529366dca9ac",
     "grade": false,
     "grade_id": "cell-4a11661adce06bcb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell will run all the answer cells\n",
    "%reset -f\n",
    "from IPython.display import Javascript\n",
    "display(Javascript(\"Jupyter.notebook.execute_cells([2, 6, 9, 12, 15, 18, 28, 31, 34, 42, 45, 51, 54, 57, 60, 63, 67, 71, 80])\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1dd6de",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "76d1e31d80448d0f4027cde9d2bed4f4",
     "grade": false,
     "grade_id": "cell-b2d3d17d61b22258",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell will run the initial tests for questions\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from termcolor import colored\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
    "from ca_utils import load_interest_points\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Test data\n",
    "dummy_1 = np.random.randint(0, 255, size=(750, 750, 3), dtype=\"uint8\")\n",
    "dummy_2 = np.random.randint(0, 255, size=(750, 750), dtype=\"uint8\")\n",
    "k = np.random.randint(0, 2, size=(3, 3), dtype=\"uint8\")\n",
    "shapes = cv2.cvtColor(cv2.imread('data/shapes.png'), cv2.COLOR_BGR2RGB)\n",
    "points = np.load('data/points.npy')\n",
    "notre_dame_1 = cv2.cvtColor(cv2.imread('data/notre_dame_1.jpg'), cv2.COLOR_BGR2RGB)\n",
    "notre_dame_2 = cv2.cvtColor(cv2.imread('data/notre_dame_2.jpg'), cv2.COLOR_BGR2RGB)\n",
    "x1, y1, x2, y2 = load_interest_points('data/notre_dame_1_to_notre_dame_2.pkl')\n",
    "N = 10000\n",
    "nC = 100\n",
    "X = np.random.randint(notre_dame_1.shape[1], size=(N, 1))\n",
    "Y = np.random.randint(notre_dame_1.shape[0], size=(N, 1))\n",
    "locations = np.concatenate((X, Y), axis=1)\n",
    "clusters = np.random.randint(nC, size=N)\n",
    "U = np.random.randint(50, size=(10, 50))\n",
    "V = np.random.randint(50, size=(20, 50))\n",
    "class CheckPointDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __getitem__(self, item):\n",
    "        return self.data[item]\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "test_data = CheckPointDataset(torch.rand(8, 3, 224, 224))\n",
    "test_loader = DataLoader(test_data, batch_size=2)\n",
    "p1 = np.random.randint(0, 226, (100, 2), dtype=\"uint8\")\n",
    "p2 = np.random.randint(0, 226, (100, 2), dtype=\"uint8\")\n",
    "R1 = np.array([[0.9903, 0.0000, -0.1392], [0.0242, 0.9848, 0.1720]], dtype=np.float32)\n",
    "R2 = np.array([[1.0000, 0.0000, 0.00000], [0.0000, 0.9848, 0.1736]], dtype=np.float32)\n",
    "T1 = np.array([500, 160], dtype=np.float32)\n",
    "T2 = np.array([500, 160], dtype=np.float32)\n",
    "\n",
    "# Q1 initial test\n",
    "try:\n",
    "    output_1 = add_gaussian_noise(dummy_1, 0.0, 0.0)\n",
    "    if isinstance(output_1, np.ndarray) and output_1.shape == (750, 750, 3) and output_1.dtype == \"uint8\":\n",
    "        print(colored(\"Q1. The 'add_gaussian_noise' function has passed the initial test.\", \"green\"))\n",
    "    else:\n",
    "        print(colored(\"Q1. The 'add_gaussian_noise' function cannot pass the initial test.\", \"red\"))\n",
    "except (NotImplementedError, NameError):\n",
    "    print(colored(\"Q1. The 'add_gaussian_noise' function cannot be found.\", \"red\"))\n",
    "\n",
    "# Q2 initial test\n",
    "try:\n",
    "    output_2 = add_speckle_noise(dummy_1, 0.0, 0.0)\n",
    "    if isinstance(output_2, np.ndarray) and output_2.shape == (750, 750, 3) and output_2.dtype == \"uint8\":\n",
    "        print(colored(\"Q2. The 'add_speckle_noise' function has passed the initial test.\", \"green\"))\n",
    "    else:\n",
    "        print(colored(\"Q2. The 'add_speckle_noise' function cannot pass the initial test.\", \"red\"))\n",
    "except (NotImplementedError, NameError):\n",
    "    print(colored(\"Q2. The 'add_speckle_noise' function cannot be found.\", \"red\"))\n",
    "\n",
    "# Q3 initial test\n",
    "try:\n",
    "    output_3 = cal_image_hist(dummy_2)\n",
    "    if isinstance(output_3, np.ndarray) and output_3.ndim == 1 and output_3.shape[0] > 1:\n",
    "        print(colored(\"Q3. The 'cal_image_hist' function has passed the initial test.\", \"green\"))\n",
    "    else:\n",
    "        print(colored(\"Q3. The 'cal_image_hist' function cannot pass the initial test.\", \"red\"))\n",
    "except (NotImplementedError, NameError):\n",
    "    print(colored(\"Q3. The 'cal_image_hist' function cannot be found.\", \"red\"))\n",
    "\n",
    "# Q4 initial test\n",
    "try:\n",
    "    output_4 = compute_gradient_magnitude(dummy_2, k, k)\n",
    "    if isinstance(output_4, np.ndarray) and output_4.shape == (750, 750) and output_4.dtype == \"float64\":\n",
    "        print(colored(\"Q4. The 'compute_gradient_magnitude' function has passed the initial test.\", \"green\"))\n",
    "    else:\n",
    "        print(colored(\"Q4. The 'compute_gradient_magnitude' function cannot pass the initial test.\", \"red\"))\n",
    "except (NotImplementedError, NameError):\n",
    "    print(colored(\"Q4. The 'compute_gradient_magnitude' function cannot be found.\", \"red\"))\n",
    "\n",
    "# Q5 initial test\n",
    "try:\n",
    "    output_5 = compute_gradient_direction(dummy_2, k, k)\n",
    "    if isinstance(output_5, np.ndarray) and output_5.shape == (750, 750) and output_5.dtype == \"float64\":\n",
    "        print(colored(\"Q5. The 'compute_gradient_direction' function has passed the initial test.\", \"green\"))\n",
    "    else:\n",
    "        print(colored(\"Q5. The 'compute_gradient_direction' function cannot pass the initial test.\", \"red\"))\n",
    "except (NotImplementedError, NameError):\n",
    "    print(colored(\"Q5. The 'compute_gradient_direction' function cannot be found.\", \"red\"))\n",
    "\n",
    "# Q6 initial test\n",
    "try:\n",
    "    output_6 = detect_harris_corner(shapes)\n",
    "    if isinstance(output_6, np.ndarray) and output_6[0].shape[0] > 1 and output_6[0].dtype == \"int64\":\n",
    "        print(colored(\"Q6. The 'detect_harris_corner' function has passed the initial test.\", \"green\"))\n",
    "    else:\n",
    "        print(colored(\"Q6. The 'detect_harris_corner' function cannot pass the initial test.\", \"red\"))\n",
    "except (NotImplementedError, NameError):\n",
    "    print(colored(\"Q6. The 'detect_harris_corner' function cannot be found.\", \"red\"))\n",
    "\n",
    "# Q7 initial test\n",
    "try:\n",
    "    output_7 = compute_homogeneous_rotation_matrix(points, 30)\n",
    "    if isinstance(output_7, np.ndarray) and output_7.ndim == 2 and output_7.dtype == \"float64\":\n",
    "        print(colored(\"Q7. The 'compute_homogeneous_rotation_matrix' function has passed the initial test.\", \"green\"))\n",
    "    else:\n",
    "        print(colored(\"Q7. The 'compute_homogeneous_rotation_matrix' function cannot pass the initial test.\", \"red\"))\n",
    "except (NotImplementedError, NameError):\n",
    "    print(colored(\"Q7. The 'compute_homogeneous_rotation_matrix' function cannot be found.\", \"red\"))\n",
    "\n",
    "# Q8 initial test\n",
    "try:\n",
    "    output_8 = compute_sift(notre_dame_1, x1, y1)\n",
    "    if isinstance(output_8, np.ndarray) and output_8.ndim == 2 and output_8.dtype == \"float64\":\n",
    "        print(colored(\"Q8. The 'compute_sift' function has passed the initial test.\", \"green\"))\n",
    "    else:\n",
    "        print(colored(\"Q8. The 'compute_sift' function cannot pass the initial test.\", \"red\"))\n",
    "except (NotImplementedError, NameError):\n",
    "    print(colored(\"Q8. The 'compute_sift' function cannot be found.\", \"red\"))\n",
    "\n",
    "# Q9 initial test\n",
    "try:\n",
    "    output_9 = compute_sift(notre_dame_2, x2, y2)\n",
    "    output_10 = match_features(output_8, output_9, x1, y1, x2, y2)\n",
    "    if isinstance(output_10, tuple) and isinstance(output_10[0], np.ndarray) and output_10[0].ndim == 2 and output_10[0].dtype == \"int64\" and isinstance(output_10[1], np.ndarray) and output_10[1].ndim == 1 and output_10[1].dtype == \"float64\":\n",
    "        print(colored(\"Q9. The 'match_features' function has passed the initial test.\", \"green\"))\n",
    "    else:\n",
    "        print(colored(\"Q9. The 'match_features' function cannot pass the initial test.\", \"red\"))\n",
    "except (NotImplementedError, NameError):\n",
    "    print(colored(\"Q9. The 'match_features' function cannot be found.\", \"red\"))\n",
    "\n",
    "# Q10 initial test\n",
    "try:\n",
    "    output_11 = find_affine_transform(x1, y1, x2, y2)\n",
    "    if isinstance(output_11, np.ndarray) and output_11.shape == (3, 3) and output_11.dtype == \"float64\":\n",
    "        print(colored(\"Q10. The 'find_affine_transform' function has passed the initial test.\", \"green\"))\n",
    "    else:\n",
    "        print(colored(\"Q10. The 'find_affine_transform' function cannot pass the initial test.\", \"red\"))\n",
    "except (NotImplementedError, NameError):\n",
    "    print(colored(\"Q10. The 'find_affine_transform' function cannot be found.\", \"red\"))\n",
    "\n",
    "# Q11 initial test\n",
    "try:\n",
    "    output_12 = make_bovw_spatial_histogram(notre_dame_1, locations, clusters, [2, 2])\n",
    "    if isinstance(output_12, np.ndarray) and output_12.ndim == 1 and output_12.shape[0] > 1 and output_12.dtype == \"int64\":\n",
    "        print(colored(\"Q11. The 'make_bovw_spatial_histogram' function has passed the initial test.\", \"green\"))\n",
    "    else:\n",
    "        print(colored(\"Q11. The 'make_bovw_spatial_histogram' function cannot pass the initial test.\", \"red\"))\n",
    "except (NotImplementedError, NameError):\n",
    "    print(colored(\"Q11. The 'make_bovw_spatial_histogram' function cannot be found.\", \"red\"))\n",
    "\n",
    "# Q12 initial test\n",
    "try:\n",
    "    output_13 = histogram_intersection_kernel(U, V)\n",
    "    if isinstance(output_13, np.ndarray) and output_13.ndim == 2 and output_13.dtype == \"float64\":\n",
    "        print(colored(\"Q12. The 'histogram_intersection_kernel' function has passed the initial test.\", \"green\"))\n",
    "    else:\n",
    "        print(colored(\"Q12. The 'histogram_intersection_kernel' function cannot pass the initial test.\", \"red\"))\n",
    "except (NotImplementedError, NameError):\n",
    "    print(colored(\"Q12. The 'histogram_intersection_kernel' function cannot be found.\", \"red\"))\n",
    "\n",
    "# Q13 initial test\n",
    "try:\n",
    "    output_14 = generalized_histogram_intersection_kernel(U, V, 0.6)\n",
    "    if isinstance(output_14, np.ndarray) and output_14.ndim == 2 and output_14.dtype == \"float64\":\n",
    "        print(colored(\"Q13. The 'generalized_histogram_intersection_kernel' function has passed the initial test.\", \"green\"))\n",
    "    else:\n",
    "        print(colored(\"Q13. The 'generalized_histogram_intersection_kernel' function cannot pass the initial test.\", \"red\"))\n",
    "except (NotImplementedError, NameError):\n",
    "    print(colored(\"Q13. The 'generalized_histogram_intersection_kernel' function cannot be found.\", \"red\"))\n",
    "\n",
    "# Q14 initial test\n",
    "try:\n",
    "    output_15 = train_gram_matrix(U, V)\n",
    "    if isinstance(output_15, np.ndarray) and output_15.ndim == 2 and output_15.dtype == \"float64\":\n",
    "        print(colored(\"Q14. The 'train_gram_matrix' function has passed the initial test.\", \"green\"))\n",
    "    else:\n",
    "        print(colored(\"Q14. The 'train_gram_matrix' function cannot pass the initial test.\", \"red\"))\n",
    "except (NotImplementedError, NameError):\n",
    "    print(colored(\"Q14. The 'train_gram_matrix' function cannot be found.\", \"red\"))\n",
    "\n",
    "# Q15 initial test\n",
    "try:\n",
    "    output_16 = test_gram_matrix(U, V)\n",
    "    if isinstance(output_16, np.ndarray) and output_16.ndim == 2 and output_16.dtype == \"float64\":\n",
    "        print(colored(\"Q15. The 'test_gram_matrix' function has passed the initial test.\", \"green\"))\n",
    "    else:\n",
    "        print(colored(\"Q15. The 'test_gram_matrix' function cannot pass the initial test.\", \"red\"))\n",
    "except (NotImplementedError, NameError):\n",
    "    print(colored(\"Q15. The 'test_gram_matrix' function cannot be found.\", \"red\"))\n",
    "\n",
    "# Q16 initial test\n",
    "try:\n",
    "    output_17 = reconstruct_3d(p1, p2, R1, R2, T1, T2)\n",
    "    if isinstance(output_17, np.ndarray) and output_17.shape == (p1.shape[0], 3) and output_17.dtype == \"float32\":\n",
    "        print(colored(\"Q16. The 'reconstruct_3d' function has passed the initial test.\", \"green\"))\n",
    "    else:\n",
    "        print(colored(\"Q16. The 'reconstruct_3d' function cannot pass the initial test.\", \"red\"))\n",
    "except (NotImplementedError, NameError):\n",
    "    print(colored(\"Q16. The 'reconstruct_3d' function cannot be found.\", \"red\"))\n",
    "\n",
    "# Q17 initial test\n",
    "flag1 = os.path.isfile(\"data/weights_resnet.pth\")\n",
    "try:\n",
    "    from ca_utils import ResNet, BasicBlock\n",
    "    model = ResNet(block=BasicBlock, layers=[1, 1, 1], num_classes=10)\n",
    "    cp = torch.load(\"data/weights_resnet.pth\", map_location=torch.device(\"cpu\"))\n",
    "    model.load_state_dict(cp)\n",
    "    flag2 = True\n",
    "except (FileNotFoundError):\n",
    "    flag2 = False\n",
    "if flag1 and flag2:\n",
    "    print(colored(\"Q17. The 'train_cnn' function has passed the initial test.\", \"green\"))\n",
    "else:\n",
    "    print(colored(\"Q17. The 'train_cnn' function cannot pass the initial test.\", \"red\"))\n",
    "\n",
    "# Q18 initial test\n",
    "try:\n",
    "    output_18 = test_cnn(model, test_loader)\n",
    "    flag3 = True\n",
    "except (NotImplementedError, NameError):\n",
    "    flag3 = False\n",
    "if flag3 and isinstance(output_18, np.ndarray) and output_18.ndim == 1 and output_18.shape == (len(test_data),) and output_18.dtype == \"int64\":\n",
    "    print(colored(\"Q18. The 'test_cnn' function has passed the initial test.\", \"green\"))\n",
    "else:\n",
    "    print(colored(\"Q18. The 'test_cnn' function cannot pass the initial test.\", \"red\"))\n",
    "\n",
    "# Q19 initial test\n",
    "try:\n",
    "    output_19 = count_masks(test_data)\n",
    "    if isinstance(output_19, np.ndarray) and output_19.shape == (len(test_data), 3) and output_19.dtype == \"int64\":\n",
    "        print(colored(\"Q19. The 'count_masks' function has passed the initial test.\", \"green\"))\n",
    "    else:\n",
    "        print(colored(\"Q19. The 'count_masks' function cannot pass the initial test.\", \"red\"))\n",
    "except (NotImplementedError, NameError):\n",
    "    print(colored(\"Q19. The 'count_masks' function cannot be found.\", \"red\"))\n",
    "\n",
    "# Execution time should be less than 1 minute\n",
    "tot_time = time.time() - start_time\n",
    "if tot_time > 60:\n",
    "    print(colored(\"Execution took {} which is higher than the time limit and should be within {}.\".format(time.strftime(\"%H:%M:%S\", time.gmtime(tot_time)), time.strftime(\"%H:%M:%S\", time.gmtime(120.0))), \"red\"))\n",
    "else:\n",
    "    print(colored(\"Execution took {} which met the time criteria.\".format(time.strftime(\"%H:%M:%S\", time.gmtime(tot_time))), \"green\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7706f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
